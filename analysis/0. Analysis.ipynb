{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(path / \"assets/datasets/dataset-1.csv\", delimiter=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.classification import Classification\n",
    "\n",
    "clf = Classification(n_jobs=4, verbose=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pipeline.classification import DEFAULT_POS\n",
    "\n",
    "X = list(df[\"texts\"])\n",
    "y = list(df[\"targets\"])\n",
    "\n",
    "# X, _1, y, _2 = train_test_split(\n",
    "#     X,\n",
    "#     y,\n",
    "#     train_size=.05,\n",
    "#     random_state=42,\n",
    "#     stratify=y\n",
    "# )\n",
    "\n",
    "X_cleaned = clf.clean(X)\n",
    "\n",
    "# X_tokenized = clf.tokenize(X_cleaned)\n",
    "X_tokenized = clf.tokenize(X_cleaned, list(set(DEFAULT_POS) - set([\"DET\",\"INTJ\",\"NUM\",\"PRON\",\"PROPN\",\"PUNCT\",\"X\"])))\n",
    "\n",
    "X_train, X_test, y_train, y_test = clf.train_test_split(X_tokenized, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "grid_search, estimation = clf.tuning(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    [\n",
    "        {\n",
    "            \"tfidfvectorizer__ngram_range\": ((1, 1),(1,2)),\n",
    "            \"tfidfvectorizer__min_df\": (1, 3, 5, 10),\n",
    "            \"tfidfvectorizer__max_df\": (0.2, 0.4, 0.6, 0.8, 1.0),\n",
    "            \"svc__kernel\": (\"linear\",),\n",
    "            \"svc__C\": (0.01, 0.1, 1, 10, 100, 1000, 10000)\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "res = {\n",
    "    \"estimation\": estimation,\n",
    "    \"grid_search\": grid_search\n",
    "}\n",
    "\n",
    "with open(path / f\"assets/pickles/hyper-parameter-tuning:{round(time.time()*1000)}.pickle\", \"wb\") as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.train(X_train, y_train, grid_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.test(model, X_test)\n",
    "accuracy, mcc = clf.score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6177d1207e3b4e003bd5f7e0d0e470f696ef2c8899bc099ae3ccb41c3d6c53a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
