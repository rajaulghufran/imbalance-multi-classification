{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\c10nGp4\\OneDrive\\Documents\\GitHub\\imbalance-multi-classification\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training set\n",
    "training_set_df = pd.read_csv(path / \"assets/datasets/training-set-1.csv\", delimiter=\";\")\n",
    "\n",
    "# Get X and y from dataset\n",
    "X_train = list(training_set_df[\"texts\"])\n",
    "y_train = list(training_set_df[\"targets\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfe86c88f59485bae0c9364d6f79b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 10:45:45 INFO: Downloading default packages for language: id (Indonesian) ...\n",
      "2023-06-14 10:45:45 INFO: File exists: C:\\Users\\c10nGp4\\stanza_resources\\id\\default.zip\n",
      "2023-06-14 10:45:47 INFO: Finished downloading models and saved to C:\\Users\\c10nGp4\\stanza_resources.\n",
      "2023-06-14 10:45:47 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7eedac9f2547debee871d6a74e976b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bea2319e15410c81b174f47e377efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.5.0/models/pos/gsd.pt:   0%|          | 0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 10:45:53 INFO: Loading these models for language: id (Indonesian):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | gsd     |\n",
      "| mwt       | gsd     |\n",
      "| pos       | gsd     |\n",
      "| lemma     | gsd     |\n",
      "=======================\n",
      "\n",
      "2023-06-14 10:45:53 INFO: Using device: cuda\n",
      "2023-06-14 10:45:53 INFO: Loading: tokenize\n",
      "2023-06-14 10:45:55 INFO: Loading: mwt\n",
      "2023-06-14 10:45:55 INFO: Loading: pos\n",
      "2023-06-14 10:45:55 INFO: Loading: lemma\n",
      "2023-06-14 10:45:55 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from pipeline.text_cleaning import TextCleaning\n",
    "from pipeline.tokenize_mwt_pos_lemma import TokenizeMWTPOSLemma\n",
    "\n",
    "text_preprocessing_pipeline: Pipeline = Pipeline([\n",
    "    (\"text_cleaning\", TextCleaning(verbose=0)),\n",
    "    (\"tokenize_mwt_pos_lemma\", TokenizeMWTPOSLemma(verbose=0))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters tuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def fun(arg):\n",
    "    return arg\n",
    "\n",
    "tfidfvectorizer_hyperparameters = {\n",
    "    \"encoding\": \"ascii\",\n",
    "    \"decode_error\": \"ignore\",\n",
    "    \"strip_accents\": \"ascii\",\n",
    "    \"preprocessor\": fun,\n",
    "    \"tokenizer\": fun,\n",
    "    \"analyzer\": \"word\",\n",
    "    \"token_pattern\": None,\n",
    "    \"ngram_range\": (1, 1),\n",
    "    \"min_df\": 1,\n",
    "    \"max_df\": 1.0,\n",
    "    \"norm\": \"l2\",\n",
    "    \"sublinear_tf\": False\n",
    "}\n",
    "\n",
    "linearsvc_hyperparameters = {\n",
    "    \"loss\": \"squared_hinge\",\n",
    "    \"dual\": False,\n",
    "    \"multi_class\": \"ovr\",\n",
    "    \"max_iter\": 1000000,\n",
    "    \"random_state\": 42,\n",
    "    \"tol\": 0.0001,\n",
    "    \"penalty\": \"l2\",\n",
    "    \"C\": 1,\n",
    "    \"fit_intercept\": True,\n",
    "    \"intercept_scaling\": 1.0,\n",
    "    \"class_weight\": \"balanced\"\n",
    "}\n",
    "\n",
    "classification_pipeline: Pipeline = Pipeline([\n",
    "    (\"tfidfvectorizer\", TfidfVectorizer(**tfidfvectorizer_hyperparameters)),\n",
    "    (\"linearsvc\", LinearSVC(**linearsvc_hyperparameters))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import make_scorer, accuracy_score, matthews_corrcoef\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from pipeline.pos_filter import POS\n",
    "from pipeline.data.stopwords import STOPWORDS\n",
    "from pipeline.pos_filter import POSFilter\n",
    "from pipeline.stopword_removal import StopWordRemoval\n",
    "from pipeline.document_transformer import DocumentTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "# warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "n_iter = 10000\n",
    "n_splits = 5\n",
    "train_size = 0.8\n",
    "n_jobs = 1\n",
    "verbose = 0\n",
    "\n",
    "results=[]\n",
    "\n",
    "for pipe, params in [\n",
    "    (\n",
    "        \"pos_filter\",\n",
    "        [\n",
    "            {\"pos\": (\"ADJ\",\"ADV\",\"NOUN\",\"PART\",\"VERB\")},\n",
    "            {\"pos\": POS}\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        \"stopword_removal\",\n",
    "        [\n",
    "            {\"stopwords\": STOPWORDS},\n",
    "            {\"stopwords\": None}\n",
    "        ]\n",
    "    ),\n",
    "    (\n",
    "        \"document_transformer\",\n",
    "        [\n",
    "            {\"feat_attrs\": [\"text\"]},\n",
    "            {\"feat_attrs\": [\"lemma\"]},\n",
    "            {\"feat_attrs\": [\"text\",\"upos\"]},\n",
    "            {\"feat_attrs\": [\"lemma\",\"upos\"]}\n",
    "        ]\n",
    "    )\n",
    "]:\n",
    "    for param in params:\n",
    "        feature_selection_pipeline: Pipeline = Pipeline([\n",
    "            (\"pos_filter\", POSFilter(**{\"pos\": (\"ADJ\",\"ADV\",\"NOUN\",\"PART\",\"VERB\")}, verbose=0)),\n",
    "            (\"stopword_removal\", StopWordRemoval(**{\"stopwords\": STOPWORDS}, verbose=0)),\n",
    "            (\"document_transformer\", DocumentTransformer(**{\"feat_attrs\": [\"lemma\",\"upos\"]}, verbose=0))\n",
    "        ])\n",
    "        feature_selection_pipeline.named_steps[pipe].set_params(**param)\n",
    "\n",
    "        X_temp = text_preprocessing_pipeline.transform(X_train)\n",
    "        X_temp = feature_selection_pipeline.transform(X_temp)\n",
    "\n",
    "        cv = cross_validate(\n",
    "            classification_pipeline,\n",
    "            X_temp,\n",
    "            y_train,\n",
    "            scoring=make_scorer(matthews_corrcoef),\n",
    "            cv=StratifiedShuffleSplit(n_splits=n_splits, train_size=train_size, random_state=42),\n",
    "            n_jobs=n_jobs,\n",
    "            verbose=verbose,\n",
    "            return_estimator=True\n",
    "        )\n",
    "\n",
    "        col_names = [\n",
    "            \"split0_test_score\",\"split1_test_score\",\"split2_test_score\",\"split3_test_score\",\"split4_test_score\",\"mean_test_score\",\n",
    "            \"mean_fit_time\"\n",
    "        ]\n",
    "\n",
    "        results.append((\n",
    "            param,\n",
    "            len(cv[\"estimator\"][cv[\"test_score\"].tolist().index(max(cv[\"test_score\"].tolist()))].named_steps[\"tfidfvectorizer\"].vocabulary_),\n",
    "            pd.DataFrame({k: v for k, v in cv.items() if k not in [\"estimator\", \"score_time\"]})\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos': ('ADJ', 'ADV', 'NOUN', 'PART', 'VERB')}\n",
      "7309\n",
      "0.23271293640136717\n",
      "0.602673158318661\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.238964  0.236616  0.239463  0.231777  0.216743\n",
      "test_score  0.601934  0.599224  0.598257  0.602419  0.611532\n",
      "\n",
      "{'pos': {'AUX', 'CCONJ', 'NOUN', 'PROPN', 'ADP', 'ADJ', 'ADV', 'SYM', 'PART', 'VERB', 'X', 'NUM', 'PUNCT', 'DET', 'INTJ', 'SCONJ', 'PRON'}}\n",
      "8087\n",
      "0.3093985080718994\n",
      "0.6025636567351069\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.319655  0.324573  0.287171  0.304089  0.311505\n",
      "test_score  0.601963  0.596623  0.603343  0.604974  0.605915\n",
      "\n",
      "{'stopwords': {'berdatangan', 'dibuat', 'dimisalkan', 'setibanya', 'dikarenakan', 'ibaratnya', 'rasanya', 'ditunjuki', 'kedua', 'menantikan', 'sebagai', 'harus', 'kelihatannya', 'kata', 'jadi', 'meyakini', 'berjumlah', 'padahal', 'beginilah', 'sepanjang', 'kalau', 'beri', 'bersama', 'berakhirlah', 'enggaknya', 'kan', 'pertama-tama', 'kini', 'selama-lamanya', 'satu', 'jikalau', 'didatangkan', 'gunakan', 'mengetahui', 'mungkin', 'kiranya', 'misalnya', 'sudahlah', 'tegasnya', 'sangat', 'setidaknya', 'dimaksudkannya', 'dirinya', 'menanyakan', 'menuju', 'kasus', 'sebegini', 'tersampaikan', 'selalu', 'perlu', 'pernah', 'seluruh', 'mempunyai', 'dekat', 'dikerjakan', 'kenapa', 'dikatakannya', 'bapak', 'karena', 'memihak', 'sesama', 'sampai', 'segala', 'tetap', 'menyiapkan', 'berbagai', 'sebelumnya', 'diantaranya', 'enggak', 'caranya', 'telah', 'saling', 'antaranya', 'benar', 'berkehendak', 'lagi', 'kapan', 'sana', 'sekarang', 'beberapa', 'segera', 'berakhir', 'pertanyaan', 'ada', 'diminta', 'menyebutkan', 'mempertanyakan', 'atau', 'itu', 'tadi', 'percuma', 'diketahui', 'jelas', 'hendaknya', 'berturut-turut', 'maka', 'sepertinya', 'keluar', 'digunakan', 'memulai', 'tandasnya', 'jangan', 'demikian', 'keseluruhan', 'benarkah', 'masalahnya', 'sekitar', 'artinya', 'hampir', 'kepadanya', 'sekitarnya', 'diingatkan', 'sebegitu', 'umum', 'pun', 'menggunakan', 'mempersoalkan', 'biasa', 'jawaban', 'dipunyai', 'mendapat', 'mengapa', 'sama-sama', 'dibuatnya', 'adalah', 'kala', 'tiap', 'tak', 'macam', 'malahan', 'disebut', 'maupun', 'menginginkan', 'punya', 'sebab', 'cukupkah', 'dikatakan', 'minta', 'tetapi', 'dimulailah', 'padanya', 'jauh', 'seusai', 'cuma', 'pak', 'nyatanya', 'waduh', 'berlebihan', 'seringnya', 'dipergunakan', 'terus', 'daripada', 'itulah', 'nah', 'merekalah', 'mulai', 'buat', 'sinilah', 'dimulai', 'sepihak', 'semua', 'dia', 'betulkah', 'mengerjakan', 'katanya', 'mula', 'sewaktu', 'khususnya', 'meski', 'segalanya', 'ingat-ingat', 'memberikan', 'tentang', 'kamulah', 'ke', 'mampukah', 'bersiap-siap', 'mengatakan', 'sejauh', 'lima', 'teringat-ingat', 'kalian', 'semacam', 'hendaklah', 'seperti', 'sudahkah', 'saja', 'setengah', 'tidak', 'bisa', 'itukah', 'jawabnya', 'setempat', 'ditunjuk', 'jelaslah', 'sebenarnya', 'sendiri', 'entahlah', 'wahai', 'aku', 'memperbuat', 'melalui', 'mereka', 'sampaikan', 'bisakah', 'ditunjuknya', 'mendapatkan', 'menegaskan', 'menurut', 'keseluruhannya', 'bulan', 'diperlihatkan', 'bertanya-tanya', 'asal', 'tentulah', 'tersebut', 'dini', 'para', 'kalaupun', 'serupa', 'begitu', 'merupakan', 'diperlukannya', 'rupanya', 'sekecil', 'ibaratkan', 'boleh', 'setelah', 'bagaimanapun', 'balik', 'sesuatunya', 'tanyakan', 'memastikan', 'mengakhiri', 'seingat', 'naik', 'biasanya', 'pastilah', 'setiap', 'ataukah', 'olehnya', 'bukan', 'kurang', 'sangatlah', 'terdahulu', 'setinggi', 'bukanlah', 'bagai', 'sama', 'masihkah', 'pada', 'justru', 'terasa', 'dilakukan', 'semisalnya', 'kembali', 'hanyalah', 'yaitu', 'setiba', 'lamanya', 'didapat', 'melakukan', 'tampaknya', 'seorang', 'kelihatan', 'bolehlah', 'disebutkan', 'sambil', 'cukup', 'dapat', 'misal', 'tiba-tiba', 'merasa', 'seketika', 'se', 'selain', 'turut', 'banyak', 'ditandaskan', 'menyangkut', 'makanya', 'berkeinginan', 'sekalian', 'mengatakannya', 'inginkan', 'bermacam-macam', 'entah', 'memerlukan', 'diibaratkan', 'dong', 'berturut', 'diucapkannya', 'diberi', 'berawal', 'ditambahkan', 'datang', 'sekiranya', 'usah', 'tiba', 'dituturkan', 'persoalan', 'adapun', 'mendatangkan', 'ditujukan', 'saatnya', 'memintakan', 'dahulu', 'sesekali', 'mengibaratkannya', 'berlainan', 'mirip', 'dimulainya', 'sayalah', 'bagaikan', 'lebih', 'lama', 'masing-masing', 'menghendaki', 'semula', 'inilah', 'mengibaratkan', 'sudah', 'depan', 'terlihat', 'sebaik-baiknya', 'menanyai', 'umumnya', 'haruslah', 'cukuplah', 'diperkirakan', 'baik', 'pertama', 'rasa', 'bung', 'siapa', 'akhirnya', 'dikira', 'sebuah', 'usai', 'disampaikan', 'diucapkan', 'bermula', 'bersiap', 'kesampaian', 'menunjuki', 'bahkan', 'pula', 'keadaan', 'dijelaskan', 'berapakah', 'awal', 'bahwa', 'berlangsung', 'karenanya', 'sepantasnya', 'kemungkinan', 'apakah', 'mulanya', 'sedikitnya', 'suatu', 'tersebutlah', 'sajalah', 'mengucapkannya', 'sebaik', 'bukannya', 'belakang', 'bagaimanakah', 'dilihat', 'bukankah', 'keduanya', 'meskipun', 'diakhiri', 'semaunya', 'tidaklah', 'masa', 'semampunya', 'pasti', 'tiga', 'berakhirnya', 'diperbuat', 'selama', 'ditanyakan', 'ataupun', 'pukul', 'sejenak', 'dipertanyakan', 'seolah-olah', 'akulah', 'diperbuatnya', 'tuturnya', 'terutama', 'semampu', 'dijelaskannya', 'semata', 'wong', 'sendirian', 'manalagi', 'terjadi', 'akankah', 'dimungkinkan', 'kemungkinannya', 'agak', 'dimaksudnya', 'mulailah', 'siap', 'hingga', 'seperlunya', 'dimintai', 'jumlah', 'hanya', 'sering', 'setidak-tidaknya', 'menanti-nanti', 'kami', 'walau', 'kira-kira', 'bahwasanya', 'dipastikan', 'saat', 'sebelum', 'sesudahnya', 'tunjuk', 'mengingat', 'ditanyai', 'amat', 'ternyata', 'terhadap', 'ditanya', 'tinggi', 'bagaimana', 'dijawab', 'berapalah', 'sesuatu', 'penting', 'seluruhnya', 'sendirinya', 'tambahnya', 'bertutur', 'sebabnya', 'memisalkan', 'akhir', 'tepat', 'tertentu', 'menunjuk', 'dan', 'berujar', 'masalah', 'ujarnya', 'namun', 'per', 'menambahkan', 'soalnya', 'diri', 'belakangan', 'meminta', 'benarlah', 'tengah', 'semata-mata', 'tambah', 'akan', 'mengira', 'asalkan', 'kamilah', 'selanjutnya', 'dimaksud', 'seenaknya', 'apaan', 'diinginkan', 'yakni', 'selaku', 'bagian', 'keinginan', 'kita', 'mengingatkan', 'semasa', 'sebagian', 'sekali', 'berarti', 'nanti', 'kok', 'disebutkannya', 'ialah', 'sepantasnyalah', 'terbanyak', 'sebesar', 'jelasnya', 'ujar', 'memang', 'sebagainya', 'sedemikian', 'bakalan', 'lainnya', 'jawab', 'janganlah', 'mengenai', 'tentu', 'hendak', 'menaiki', 'menjelaskan', 'lanjut', 'untuk', 'lagian', 'nantinya', 'panjang', 'supaya', 'termasuk', 'sesegera', 'dituturkannya', 'belumlah', 'diibaratkannya', 'malah', 'tahu', 'lain', 'kepada', 'memperkirakan', 'mampu', 'begini', 'hal', 'diakhirinya', 'amatlah', 'awalnya', 'pihaknya', 'rata', 'kalaulah', 'saya', 'teringat', 'memungkinkan', 'agaknya', 'dimaksudkan', 'sehingga', 'diantara', 'melihatnya', 'sebut', 'melihat', 'sejak', 'tadinya', 'tanya', 'sebaiknya', 'cara', 'meyakinkan', 'ucapnya', 'sementara', 'berikut', 'inikah', 'kelamaan', 'oleh', 'lewat', 'tentunya', 'guna', 'disinilah', 'soal', 'bakal', 'sampai-sampai', 'begitulah', 'sekadarnya', 'kelima', 'berada', 'sebutlah', 'mendatang', 'sesudah', 'menanya', 'seterusnya', 'wah', 'ingat', 'akhiri', 'sebetulnya', 'menunjuknya', 'diberikannya', 'jadilah', 'membuat', 'di', 'disini', 'tanpa', 'menandaskan', 'selamanya', 'tegas', 'pihak', 'ingin', 'dari', 'menyampaikan', 'waktunya', 'empat', 'sejumlah', 'kapankah', 'makin', 'ditegaskan', 'apa', 'mendatangi', 'kebetulan', 'terdapat', 'beginikah', 'besar', 'mempergunakan', 'diingat', 'kinilah', 'sesaat', 'masih', 'tandas', 'menyatakan', 'tutur', 'pantas', 'terjadilah', 'berikutnya', 'bertanya', 'semisal', 'siapapun', 'seolah', 'berkata', 'bolehkah', 'dipersoalkan', 'waktu', 'sebagaimana', 'berkali-kali', 'agar', 'memperlihatkan', 'misalkan', 'secara', 'begitupun', 'juga', 'bila', 'berupa', 'dua', 'bawah', 'anda', 'tidakkah', 'memberi', 'lalu', 'kecil', 'inginkah', 'sebisanya', 'bekerja', 'kamu', 'menjadi', 'semakin', 'bermaksud', 'pentingnya', 'jangankan', 'masing', 'semasih', 'begitukah', 'demi', 'terakhir', 'tertuju', 'bersama-sama', 'siapakah', 'manakala', 'sekali-kali', 'mengungkapkan', 'dilalui', 'tahun', 'lah', 'dengan', 'adanya', 'katakanlah', 'ibarat', 'pertanyakan', 'ungkap', 'apatah', 'semuanya', 'sekurangnya', 'beginian', 'apabila', 'kitalah', 'kapanpun', 'berapa', 'diketahuinya', 'secukupnya', 'ia', 'ini', 'sini', 'bermacam', 'melainkan', 'ucap', 'andalah', 'tempat', 'jika', 'terkira', 'baru', 'harusnya', 'mungkinkah', 'paling', 'perlunya', 'jadinya', 'bagi', 'ketika', 'sedangkan', 'perlukah', 'menyeluruh', 'terhadapnya', 'sedang', 'kira', 'sekaligus', 'walaupun', 'dulu', 'menanti', 'katakan', 'antar', 'belum', 'menunjukkan', 'berapapun', 'mau', 'seseorang', 'seberapa', 'diungkapkan', 'menjawab', 'sekalipun', 'dialah', 'toh', 'kemudian', 'berikan', 'keterlaluan', 'sekurang-kurangnya', 'yang', 'mana', 'terlalu', 'antara', 'sela', 'terdiri', 'lanjutnya', 'mengucapkan', 'hari', 'ditunjukkan', 'sekadar', 'ungkapnya', 'ditunjukkannya', 'sebanyak', 'jumlahnya', 'mempersiapkan', 'sesampai', 'tapi', 'ibu', 'terlebih', 'tanyanya', 'bilakah', 'apalagi', 'sebaliknya', 'betul', 'atas', 'dalam', 'berkenaan', 'menuturkan', 'ikut', 'sempat', 'sedikit', 'sebutnya', 'tampak', 'yakin', 'nyaris', 'diperlukan', 'luar', 'terjadinya', 'seharusnya', 'serta', 'berlalu', 'demikianlah', 'jelaskan', 'diberikan'}}\n",
      "7309\n",
      "0.20747275352478028\n",
      "0.602673158318661\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.230756  0.212670  0.190518  0.206138  0.197283\n",
      "test_score  0.601934  0.599224  0.598257  0.602419  0.611532\n",
      "\n",
      "{'stopwords': None}\n",
      "7731\n",
      "0.22908506393432615\n",
      "0.6360352844515114\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.243923  0.225542  0.233349  0.220154  0.222458\n",
      "test_score  0.629605  0.636129  0.640236  0.631102  0.643105\n",
      "\n",
      "{'feat_attrs': ['text']}\n",
      "7908\n",
      "0.1996732234954834\n",
      "0.6172136994869405\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.219040  0.201869  0.196559  0.190674  0.190225\n",
      "test_score  0.609993  0.618348  0.614554  0.616848  0.626325\n",
      "\n",
      "{'feat_attrs': ['lemma']}\n",
      "5997\n",
      "0.1809116840362549\n",
      "0.6000712374244428\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.183749  0.172830  0.180544  0.169279  0.198157\n",
      "test_score  0.592513  0.597433  0.601136  0.606077  0.603198\n",
      "\n",
      "{'feat_attrs': ['text', 'upos']}\n",
      "8473\n",
      "0.20368432998657227\n",
      "0.6097249573760583\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.212913  0.201735  0.194732  0.207295  0.201746\n",
      "test_score  0.601387  0.610020  0.610844  0.606437  0.619937\n",
      "\n",
      "{'feat_attrs': ['lemma', 'upos']}\n",
      "7309\n",
      "0.1913334369659424\n",
      "0.602673158318661\n",
      "                   0         1         2         3         4\n",
      "fit_time    0.196587  0.186982  0.183090  0.197863  0.192145\n",
      "test_score  0.601934  0.599224  0.598257  0.602419  0.611532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (param, n, cv_results_df) in results:\n",
    "    print(param)\n",
    "    print(n)\n",
    "    print(sum(cv_results_df[\"fit_time\"]/5))\n",
    "    print(sum(cv_results_df[\"test_score\"]/5))\n",
    "    print(cv_results_df.T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ADJ', 'ADV', 'NOUN', 'PART', 'VERB')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selection_pipeline.named_steps['pos_filter'].get_params()[\"pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14160"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6177d1207e3b4e003bd5f7e0d0e470f696ef2c8899bc099ae3ccb41c3d6c53a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
